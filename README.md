# ğŸš€ C++ Unit Test Generator using LLM (Ollama + GoogleTest)

This project auto-generates unit tests for a Drogon-based C++ REST API (`orgChartApi`) using a locally hosted Large Language Model (LLM) like `tinyllama` via [Ollama](https://ollama.com/).

---

## ğŸ“ Folder Structure

cpp-unit-test-gen/
â”œâ”€â”€ orgChartApi/ # Original source code (controllers/)
â”‚ â””â”€â”€ controllers/
â”‚ â”œâ”€â”€ AuthController.cc
â”‚ â”œâ”€â”€ PersonsController.cc
â”‚ â””â”€â”€ ...
â”œâ”€â”€ tests/ # Generated + refined GoogleTest files
â”‚ â””â”€â”€ test_AuthController.cpp
â”œâ”€â”€ prompts/
â”‚ â”œâ”€â”€ initial_prompt.yaml # Prompt for test generation
â”‚ â””â”€â”€ refine_prompt.yaml # Prompt for test refinement
â”œâ”€â”€ generate_tests.py # LLM-based test generation script
â”œâ”€â”€ refine_tests.py # LLM-based test refinement script
â”œâ”€â”€ run_pipeline.sh # Full pipeline to run everything
â”œâ”€â”€ CMakeLists.txt # Build configuration
â””â”€â”€ README.md # This file

yaml
Copy
Edit

---

## ğŸ§± Prerequisites

- âœ… CMake (â‰¥ 3.10)
- âœ… GCC with `--coverage` support
- âœ… Python 3.8+
- âœ… [Ollama](https://ollama.com/) + `tinyllama` model:
  ```bash
  ollama pull tinyllama
âœ… GoogleTest installed system-wide

âš™ï¸ Setup
bash
Copy
Edit
# Clone repo and navigate
cd cpp-unit-test-gen

# Optional: Create build directory
mkdir -p build
â–¶ï¸ Run the Full Pipeline
This will:

ğŸ§ª Generate unit tests from source

ğŸ§¹ Refine them

ğŸ—ï¸ Build with CMake

âœ… Run all tests

ğŸ“Š Show coverage (if available)

bash
Copy
Edit
./run_pipeline.sh
You should see output like:

bash
Copy
Edit
âœ… Saved test: tests/test_AuthController.cpp
âœ… Saved refined test: tests/test_AuthController.cpp
[==========] Running 1 test from 1 test suite.
[  PASSED  ] 1 test.
ğŸ§ª Run Tests Only
bash
Copy
Edit
cd build
./runTests
ğŸ“ˆ Generate Code Coverage Report
bash
Copy
Edit
# Generate coverage info
lcov --capture --directory . --output-file coverage.info

# Generate HTML report
genhtml coverage.info --output-directory coverage/

# View in browser
xdg-open coverage/index.html
ğŸ” Debugging Tips
If test generation fails: check tmp/refine_failed_*.txt

If tests are skipped: your prompt or LLM response may not contain #include or TEST(...)

If no coverage: ensure you built with --coverage and ran runTests

ğŸ§  Example LLM Prompt Files
See prompts/initial_prompt.yaml and refine_prompt.yaml for examples of what is sent to the LLM.

You can tweak the prompts to:

Add test structure

Add mocking behavior

Change assertion styles

ğŸ“¬ Maintainer
Built for the Keploy AI Fellowship - Session 5
Author: Ayush @MK001